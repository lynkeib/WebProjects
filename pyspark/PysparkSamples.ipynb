{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Pyspark simple projects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in a single file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession\\\n",
    ".builder \\\n",
    ".master('local[*]') \\\n",
    ".appName('test') \\\n",
    ".getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'Data/cogsley_clients.csv'\n",
    "data = spark.sparkContext.textFile(path).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'Name,Symbol,LastSale,MarketCapLabel,MarketCapAmount,IPOyear,Sector,industry,Summary Quote',\n",
       " u'1347 Capital Corp.,TFSC,9.43,$56.09M,56090000,2014,Finance,Business Services,http://www.nasdaq.com/symbol/tfsc',\n",
       " u'1347 Capital Corp.,TFSCR,0.37,n/a,0,2014,Finance,Business Services,http://www.nasdaq.com/symbol/tfscr',\n",
       " u'1347 Capital Corp.,TFSCU,9.97,$41.67M,41670000,2014,n/a,n/a,http://www.nasdaq.com/symbol/tfscu',\n",
       " u'1347 Capital Corp.,TFSCW,0.2,n/a,0,2014,Finance,Business Services,http://www.nasdaq.com/symbol/tfscw']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "numcomputer = data.filter(lambda s:'computer' in s.lower()).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "176"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numcomputer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in mutiple files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'Data/Sales/*.csv'\n",
    "files = spark.sparkContext.wholeTextFiles(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "84"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Converst to Dataframe\n",
    "filenames = files.toDF(['name', 'data'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+\n",
      "|                name|                data|\n",
      "+--------------------+--------------------+\n",
      "|file:/Users/cheng...|36034,10/16/12,10...|\n",
      "|file:/Users/cheng...|26305,12/2/10,50,...|\n",
      "+--------------------+--------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "filenames.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|                name|\n",
      "+--------------------+\n",
      "|file:/Users/cheng...|\n",
      "|file:/Users/cheng...|\n",
      "+--------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "filenames.select('name').show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read csv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName('test').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'Data/parking-citations.csv'\n",
    "data = spark.read.csv(path).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(_c0=u'Ticket number', _c1=u'Issue Date', _c2=u'Issue time', _c3=u'Meter Id', _c4=u'Marked Time', _c5=u'RP State Plate', _c6=u'Plate Expiry Date', _c7=u'VIN', _c8=u'Make', _c9=u'Body Style', _c10=u'Color', _c11=u'Location', _c12=u'Route', _c13=u'Agency', _c14=u'Violation code', _c15=u'Violation Description', _c16=u'Fine amount', _c17=u'Latitude', _c18=u'Longitude'),\n",
       " Row(_c0=u'1103341116', _c1=u'2015-12-21T00:00:00', _c2=u'1251', _c3=None, _c4=None, _c5=u'CA', _c6=u'200304', _c7=None, _c8=u'HOND', _c9=u'PA', _c10=u'GY', _c11=u'13147 WELBY WAY', _c12=u'01521', _c13=u'1', _c14=u'4000A1', _c15=u'NO EVIDENCE OF REG', _c16=u'50', _c17=u'99999', _c18=u'99999'),\n",
       " Row(_c0=u'1103700150', _c1=u'2015-12-21T00:00:00', _c2=u'1435', _c3=None, _c4=None, _c5=u'CA', _c6=u'201512', _c7=None, _c8=u'GMC', _c9=u'VN', _c10=u'WH', _c11=u'525 S MAIN ST', _c12=u'1C51', _c13=u'1', _c14=u'4000A1', _c15=u'NO EVIDENCE OF REG', _c16=u'50', _c17=u'99999', _c18=u'99999'),\n",
       " Row(_c0=u'1104803000', _c1=u'2015-12-21T00:00:00', _c2=u'2055', _c3=None, _c4=None, _c5=u'CA', _c6=u'201503', _c7=None, _c8=u'NISS', _c9=u'PA', _c10=u'BK', _c11=u'200 WORLD WAY', _c12=u'2R2', _c13=u'2', _c14=u'8939', _c15=u'WHITE CURB', _c16=u'58', _c17=u'6439997.9', _c18=u'1802686.4'),\n",
       " Row(_c0=u'1104820732', _c1=u'2015-12-26T00:00:00', _c2=u'1515', _c3=None, _c4=None, _c5=u'CA', _c6=None, _c7=None, _c8=u'ACUR', _c9=u'PA', _c10=u'WH', _c11=u'100 WORLD WAY', _c12=u'2F11', _c13=u'2', _c14=u'000', _c15=u'17104h', _c16=None, _c17=u'6440041.1', _c18=u'1802686.2')]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-------------------+----------+--------+-----------+--------------+-----------------+----+----+----------+-----+---------------+-----+------+--------------+---------------------+-----------+--------+---------+\n",
      "|Ticket number|         Issue Date|Issue time|Meter Id|Marked Time|RP State Plate|Plate Expiry Date| VIN|Make|Body Style|Color|       Location|Route|Agency|Violation code|Violation Description|Fine amount|Latitude|Longitude|\n",
      "+-------------+-------------------+----------+--------+-----------+--------------+-----------------+----+----+----------+-----+---------------+-----+------+--------------+---------------------+-----------+--------+---------+\n",
      "|1.103341116E9|2015-12-21 00:00:00|    1251.0|    null|       null|            CA|         200304.0|null|HOND|        PA|   GY|13147 WELBY WAY|01521|   1.0|        4000A1|   NO EVIDENCE OF REG|       50.0| 99999.0|  99999.0|\n",
      "| 1.10370015E9|2015-12-21 00:00:00|    1435.0|    null|       null|            CA|         201512.0|null| GMC|        VN|   WH|  525 S MAIN ST| 1C51|   1.0|        4000A1|   NO EVIDENCE OF REG|       50.0| 99999.0|  99999.0|\n",
      "+-------------+-------------------+----------+--------+-----------+--------------+-----------------+----+----+----------+-----+---------------+-----+------+--------------+---------------------+-----------+--------+---------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.load(path,\n",
    "                    format = 'com.databricks.spark.csv',\n",
    "                    header = 'true',\n",
    "                    inferSchema = 'true')\n",
    "df.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+\n",
      "|Ticket number|\n",
      "+-------------+\n",
      "| 1.00109632E9|\n",
      "|1.001096331E9|\n",
      "+-------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select('Ticket number').distinct().orderBy('Ticket number').show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Ticket number: double (nullable = true)\n",
      " |-- Issue Date: timestamp (nullable = true)\n",
      " |-- Issue time: double (nullable = true)\n",
      " |-- Meter Id: string (nullable = true)\n",
      " |-- Marked Time: double (nullable = true)\n",
      " |-- RP State Plate: string (nullable = true)\n",
      " |-- Plate Expiry Date: double (nullable = true)\n",
      " |-- VIN: string (nullable = true)\n",
      " |-- Make: string (nullable = true)\n",
      " |-- Body Style: string (nullable = true)\n",
      " |-- Color: string (nullable = true)\n",
      " |-- Location: string (nullable = true)\n",
      " |-- Route: string (nullable = true)\n",
      " |-- Agency: double (nullable = true)\n",
      " |-- Violation code: string (nullable = true)\n",
      " |-- Violation Description: string (nullable = true)\n",
      " |-- Fine amount: double (nullable = true)\n",
      " |-- Latitude: double (nullable = true)\n",
      " |-- Longitude: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+\n",
      "|         Issue Date|\n",
      "+-------------------+\n",
      "|2015-12-21 00:00:00|\n",
      "|2015-12-21 00:00:00|\n",
      "|2015-12-21 00:00:00|\n",
      "|2015-12-26 00:00:00|\n",
      "|2015-09-15 00:00:00|\n",
      "|2015-09-15 00:00:00|\n",
      "|2015-12-17 00:00:00|\n",
      "|2015-12-17 00:00:00|\n",
      "|2015-12-22 00:00:00|\n",
      "|2015-12-22 00:00:00|\n",
      "|2015-12-22 00:00:00|\n",
      "|2015-12-22 00:00:00|\n",
      "|2015-12-22 00:00:00|\n",
      "|2015-12-15 00:00:00|\n",
      "|2015-12-27 00:00:00|\n",
      "|2015-12-27 00:00:00|\n",
      "|2015-12-27 00:00:00|\n",
      "|2015-09-16 00:00:00|\n",
      "|2015-09-16 00:00:00|\n",
      "|2015-12-22 00:00:00|\n",
      "+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select('Issue Date').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------+-----+------+\n",
      "|Violation Description|Color| count|\n",
      "+---------------------+-----+------+\n",
      "| NO PARK/STREET CLEAN|   BK|533931|\n",
      "| NO PARK/STREET CLEAN|   GY|518303|\n",
      "| NO PARK/STREET CLEAN|   WT|494940|\n",
      "|           METER EXP.|   BK|378554|\n",
      "| NO PARK/STREET CLEAN|   SL|334907|\n",
      "|           METER EXP.|   WT|319389|\n",
      "|           METER EXP.|   GY|305917|\n",
      "| NO PARK/STREET CLEAN|   BL|217495|\n",
      "|           METER EXP.|   SL|212023|\n",
      "|             RED ZONE|   WT|149514|\n",
      "| PREFERENTIAL PARKING|   BK|139212|\n",
      "| NO PARK/STREET CLEAN|   RD|132725|\n",
      "| PREFERENTIAL PARKING|   GY|132656|\n",
      "| PREFERENTIAL PARKING|   WT|122330|\n",
      "|      DISPLAY OF TABS|   BK|116122|\n",
      "|             RED ZONE|   BK|112166|\n",
      "|           METER EXP.|   BL|112126|\n",
      "|      DISPLAY OF TABS|   WT|110091|\n",
      "|             RED ZONE|   GY|102171|\n",
      "|      DISPLAY OF TABS|   GY| 98916|\n",
      "+---------------------+-----+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df\\\n",
    ".select('Violation Description', 'Color')\\\n",
    ".groupBy('Violation Description', 'Color')\\\n",
    ".count()\\\n",
    ".orderBy(desc('count'))\\\n",
    ".show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[Issue Date: timestamp, Violation Description: string, Color: string, count: bigint]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df\\\n",
    ".filter(df['Issue Date'] == '2015-12-21')\\\n",
    ".select('Issue Date', 'Violation Description', 'Color')\\\n",
    ".groupBy('Issue Date', 'Violation Description', 'Color')\\\n",
    ".count()\\\n",
    ".orderBy(desc('count'))\\\n",
    ".limit(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = df\\\n",
    ".filter(df['Issue Date'] == '2015-12-21')\\\n",
    ".select(df['Issue Date'].alias('Issue_Date'), df['Violation Description'].alias('Violation_Description'), 'Color')\\\n",
    ".groupBy('Issue_Date', 'Violation_Description', 'Color')\\\n",
    ".count()\\\n",
    ".orderBy(desc('count'))\\\n",
    ".limit(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+---------------------+-----+-----+\n",
      "|         Issue_Date|Violation_Description|Color|count|\n",
      "+-------------------+---------------------+-----+-----+\n",
      "|2015-12-21 00:00:00| NO PARK/STREET CLEAN|   BK|  702|\n",
      "|2015-12-21 00:00:00| NO PARK/STREET CLEAN|   WT|  625|\n",
      "|2015-12-21 00:00:00| NO PARK/STREET CLEAN|   GY|  624|\n",
      "|2015-12-21 00:00:00| NO PARK/STREET CLEAN|   SL|  417|\n",
      "|2015-12-21 00:00:00|           METER EXP.|   BK|  378|\n",
      "|2015-12-21 00:00:00|           METER EXP.|   WT|  337|\n",
      "|2015-12-21 00:00:00|           METER EXP.|   GY|  336|\n",
      "|2015-12-21 00:00:00| NO PARK/STREET CLEAN|   BL|  228|\n",
      "|2015-12-21 00:00:00|           METER EXP.|   SL|  222|\n",
      "|2015-12-21 00:00:00| NO PARK/STREET CLEAN|   RD|  167|\n",
      "+-------------------+---------------------+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "new_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[Issue_Date: timestamp, Violation_Description: string, Color: string, count: bigint]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql('CREATE DATABASE IF NOT EXISTS test_database')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.write.saveAsTable('test_table')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+---------------------+-----+-----+\n",
      "|         Issue_Date|Violation_Description|Color|count|\n",
      "+-------------------+---------------------+-----+-----+\n",
      "|2015-12-21 00:00:00| NO PARK/STREET CLEAN|   BK|  702|\n",
      "|2015-12-21 00:00:00| NO PARK/STREET CLEAN|   WT|  625|\n",
      "|2015-12-21 00:00:00| NO PARK/STREET CLEAN|   GY|  624|\n",
      "|2015-12-21 00:00:00| NO PARK/STREET CLEAN|   SL|  417|\n",
      "|2015-12-21 00:00:00|           METER EXP.|   BK|  378|\n",
      "|2015-12-21 00:00:00|           METER EXP.|   WT|  337|\n",
      "|2015-12-21 00:00:00|           METER EXP.|   GY|  336|\n",
      "|2015-12-21 00:00:00| NO PARK/STREET CLEAN|   BL|  228|\n",
      "|2015-12-21 00:00:00|           METER EXP.|   SL|  222|\n",
      "|2015-12-21 00:00:00| NO PARK/STREET CLEAN|   RD|  167|\n",
      "+-------------------+---------------------+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "new_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[Issue_Date: timestamp, Violation_Description: string, Color: string, count: bigint]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Table(name=u'test_table', database=u'default', description=None, tableType=u'MANAGED', isTemporary=False)]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.catalog.listTables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql('DROP TABLE IF EXISTS default.test_table')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.catalog.listTables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
