{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "review_path = \"yelp_dataset/review.json\"\n",
    "business_path = 'yelp_dataset/business.json'\n",
    "\n",
    "ss = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName('Son') \\\n",
    "    .master('local[*]') \\\n",
    "    .getOrCreate()\n",
    "\n",
    "sc = ss.sparkContext\n",
    "\n",
    "reviewRDD = sc.textFile(review_path)\n",
    "\n",
    "review = reviewRDD.map(lambda line: json.loads(line)) \\\n",
    "    .map(lambda line: (line['user_id'], line['business_id'])) \\\n",
    "    .collect()\n",
    "\n",
    "review_list = list(zip(*review))\n",
    "\n",
    "businessRDD = sc.textFile(business_path)\n",
    "\n",
    "business = businessRDD.map(lambda line: json.loads(line)) \\\n",
    "    .map(lambda line: (line['business_id'], line['state'])) \\\n",
    "    .collect()\n",
    "\n",
    "business_list = list(zip(*business))\n",
    "\n",
    "review_dict = {\"user_id\": review_list[0], \"business_id\": review_list[1]}\n",
    "business_dict = {\"business_id\": business_list[0], \"state\": business_list[1]}\n",
    "\n",
    "review_df = pd.DataFrame.from_dict(review_dict)\n",
    "business_df = pd.DataFrame.from_dict(business_dict)\n",
    "\n",
    "print(review_df.head())\n",
    "print(business_df.head())\n",
    "\n",
    "all_df = pd.merge(left=review_df, right=business_df, how='left', left_on=[\"business_id\"], right_on=['business_id'])\n",
    "\n",
    "print(all_df.head())\n",
    "\n",
    "all_df_NV = all_df[all_df['state'] == 'NV']\n",
    "\n",
    "print(all_df_NV.head())\n",
    "\n",
    "del all_df_NV['state']\n",
    "\n",
    "all_df_NV.to_csv('task2_data.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "import itertools\n",
    "import operator\n",
    "from functools import reduce\n",
    "\n",
    "\n",
    "def create_candidates(candidates_list, length):\n",
    "    '''\n",
    "    :param candidates_list:\n",
    "    :param length:\n",
    "    :return:\n",
    "    '''\n",
    "    for comb in combinations(candidates_list, 2):\n",
    "        temp = set(comb[0]) | set(comb[1])\n",
    "        if len(temp) == length:\n",
    "            yield tuple(temp)\n",
    "\n",
    "\n",
    "def frequent_items(dict, k, candidates, support):\n",
    "    '''\n",
    "    :param dict: {business_id: set(user_id)}\n",
    "    :param k: int\n",
    "    :param candidates: list[list]\n",
    "    :param support: int\n",
    "    :return: list[list]\n",
    "    '''\n",
    "    res = []\n",
    "    for comb in create_candidates(candidates, k):\n",
    "        if set(comb) not in res:\n",
    "            temp = reduce(lambda a, b: a & b, (dict[x] for x in comb))\n",
    "            if len(temp) >= support:\n",
    "                res.append(set(comb))\n",
    "    res = [list(comb) for comb in res]\n",
    "    return res\n",
    "\n",
    "\n",
    "def convert(line):\n",
    "    '''\n",
    "    :param line: (key, (values))\n",
    "    :return: list[tuple(key, value)]\n",
    "    '''\n",
    "    res = []\n",
    "    for business in line[1]:\n",
    "        res.append((business, line[0]))\n",
    "    return res\n",
    "\n",
    "\n",
    "def accumulate(l):\n",
    "    '''\n",
    "    :param l: list[tuple((key, value))]\n",
    "    :return:\n",
    "    '''\n",
    "    it = itertools.groupby(sorted(l), operator.itemgetter(0))\n",
    "    res = {}\n",
    "    for key, subiter in it:\n",
    "        res[key] = {item[1] for item in subiter}\n",
    "    return res\n",
    "\n",
    "\n",
    "def Apriori(partition, support):\n",
    "    '''\n",
    "    :param partition: iterator\n",
    "    :param support: int\n",
    "    :return: tuple(tuple(int, tuple))\n",
    "    '''\n",
    "\n",
    "    temp_partition = list(partition)\n",
    "    cand_1 = {}\n",
    "    frequent = {}\n",
    "\n",
    "    business = []\n",
    "\n",
    "    for line in temp_partition:\n",
    "        temp = convert(line)\n",
    "        business.extend(temp)\n",
    "\n",
    "    own_business_list = accumulate(business)\n",
    "\n",
    "    for line in temp_partition:\n",
    "        for item in line[1]:\n",
    "            if item not in cand_1:\n",
    "                cand_1[(item)] = 1\n",
    "            else:\n",
    "                cand_1[(item)] += 1\n",
    "\n",
    "    frequent[1] = [[key] for key, value in cand_1.items() if value >= support]\n",
    "\n",
    "    k = 2\n",
    "    while 1:\n",
    "        print(\"Creating Candidates and Frequent\", k)\n",
    "        temp_frequent = frequent_items(own_business_list, k, frequent[k - 1], support)\n",
    "        if len(temp_frequent) == 0:\n",
    "            break\n",
    "        frequent[k] = temp_frequent\n",
    "        k += 1\n",
    "    res = [(key, {frozenset(pair) for pair in value}) for key, value in frequent.items()]\n",
    "\n",
    "    return res\n",
    "\n",
    "# def global_frequent(line, candidates):\n",
    "#     '''\n",
    "#     :param line: list\n",
    "#     :param candidates: list[tuple]\n",
    "#     :return: list[tuple]\n",
    "#     '''\n",
    "#     res = []\n",
    "#     for candidate in candidates:\n",
    "#         length_set = candidate[0]\n",
    "#         items = list(candidate[1])\n",
    "#         counter = {}\n",
    "#         for item in items:\n",
    "#             if set(item).issubset(line):\n",
    "#                 if item not in counter:\n",
    "#                     counter[item] = 1\n",
    "#                 else:\n",
    "#                     counter[item] += 1\n",
    "#         res.append((length_set, counter))\n",
    "#     return res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import Apriori as A\n",
    "from functools import reduce\n",
    "\n",
    "ss = SparkSession \\\n",
    "    .builder \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .appName('SON') \\\n",
    "    .getOrCreate()\n",
    "\n",
    "sc = ss.sparkContext\n",
    "\n",
    "path = \"task2_data.csv\"\n",
    "# path = \"small2.csv\"\n",
    "\n",
    "userRDD = sc.textFile(path)\n",
    "header = userRDD.first()\n",
    "\n",
    "support = 50\n",
    "threshold = 70\n",
    "\n",
    "createCombiner = (lambda line: [line])\n",
    "mergeValue = (lambda exist, new: exist + [new])\n",
    "mergeCombiner = (lambda exist1, exist2: exist1 + exist2)\n",
    "\n",
    "userRDD = userRDD.filter(lambda line: line != header) \\\n",
    "    .map(lambda line: (line.split(',')[0], line.split(',')[1])) \\\n",
    "    .combineByKey(createCombiner, mergeValue, mergeCombiner) \\\n",
    "    .filter(lambda line: len(line[1]) >= threshold)\n",
    "\n",
    "userRDD.foreach(print)\n",
    "\n",
    "businessRDD = userRDD.flatMap(lambda line: A.convert(line)) \\\n",
    "    .groupByKey() \\\n",
    "    .mapValues(set)\n",
    "\n",
    "business = businessRDD.collect()\n",
    "businessdict = {item[0]: item[1] for item in business}\n",
    "\n",
    "numOfPar = userRDD.getNumPartitions()\n",
    "\n",
    "candidates = userRDD.mapPartitions(lambda partition: A.Apriori(partition, support / numOfPar)) \\\n",
    "    .reduceByKey(lambda a, b: a | b) \\\n",
    "    .collect()\n",
    "\n",
    "candidates = sorted([(key, sorted([list(sets) for sets in value])) for key, value in candidates])\n",
    "\n",
    "res = []\n",
    "for cand in candidates:\n",
    "    temp_1 = []\n",
    "\n",
    "    if cand[0] == 1:\n",
    "        for value in cand[1]:\n",
    "            if len(businessdict[value[0]]) >= support:\n",
    "                temp_1.append(value)\n",
    "    else:\n",
    "        for value in cand[1]:\n",
    "            temp = reduce(lambda a, b: a & b, (businessdict[x] for x in value))\n",
    "            if len(temp) >= support:\n",
    "                temp_1.append(value)\n",
    "    if len(temp_1) == 0:\n",
    "        break\n",
    "    res.append((cand[0], temp_1))\n",
    "\n",
    "print(res)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
